{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vuDAmox9ya-P"
      },
      "outputs": [],
      "source": [
        "## Carregar as Libs necessarias\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Carregar o modelo de CNN pre-treinado\n",
        "model = VGG16(weights='imagenet', include_top=False, pooling='avg')"
      ],
      "metadata": {
        "id": "NTKHmPzl0bc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b278bf1-0920-4c90-c015-5d81bc537f53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Carregar e processar imagem\n",
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "\n",
        "imagem = io.imread(\"american_bulldog_24.jpg\")\n",
        "print(imagem.shape)\n",
        "\n",
        "imagem_reduzida = resize(imagem, (128,128))\n",
        "print(imagem_reduzida.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImytVhq90njX",
        "outputId": "bd6bb9ed-c3fc-4b6a-a405-046b876b26b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(500, 334, 3)\n",
            "(128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Colocando a imagem no formato correto\n",
        "x = image.img_to_array(imagem_reduzida)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "metadata": {
        "id": "0tz2An2v5G88"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Extração de características\n",
        "features = model.predict(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqqFJEHM1ScA",
        "outputId": "52595072-7af1-4a2e-e250-f13508bfd219"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 498ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tornar as caracteristicas em forma de vetor\n",
        "features_flatten = features.flatten()\n",
        "print(features_flatten.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDk-L4tD1dgP",
        "outputId": "16b0ee65-692a-448f-b29e-cabc80a922c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512,)\n"
          ]
        }
      ]
    }
  ]
}