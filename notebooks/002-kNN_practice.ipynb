{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Carregando imagens, adicionando ao dataset, normalizando dados e treinando o modelo utilizando técnicas kNN | Aprendizado de Máquina BTI/UFRN @2023.2**\n",
        "- Tecnologies: HOG, PCA, 10-fold cv e 10-fold holdout.\n",
        "\n"
      ],
      "metadata": {
        "id": "1zKCexqgwBIQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Carregando imagens e alimentando o dataset**"
      ],
      "metadata": {
        "id": "HXmTT7dqvqZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMbDoxSCedyQ"
      },
      "outputs": [],
      "source": [
        "## Importando as libs necessárias\n",
        "from google.colab import files\n",
        "import os, io, time\n",
        "\n",
        "# Criando o diretório inicial: /content/\n",
        "os.chdir('/content/')\n",
        "try:\n",
        "  os.mkdir('Imagens', )\n",
        "except:\n",
        "  print('A pasta já existe.')\n",
        "os.chdir('./Imagens')\n",
        "os.listdir()\n",
        "uploaded_images = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HOG**"
      ],
      "metadata": {
        "id": "jj_pPw4AuWi6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfjjAWy8m7ZJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Reduzir as imagens\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "from skimage.feature import hog\n",
        "\n",
        "hog_features = []\n",
        "for filename in uploaded_images.keys():\n",
        "  image = imread(filename)\n",
        "  image_resized = resize(image, (128,128))\n",
        "  fd, hog_image = hog(image_resized, orientations=9, pixels_per_cell=(16, 16), #pode alterar o tamanho da pixels_per_cell\n",
        "                    cells_per_block=(2, 2), visualize=True, channel_axis=-1)\n",
        "  hog_features.append(fd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJQiQThUnTpe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "## Adicionar as colunas com os valores do hog\n",
        "data = {\"pathfile\": uploaded_images.keys(), \"hog_features\": hog_features}\n",
        "df = pd.DataFrame(data)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKvcqGX2niDt"
      },
      "outputs": [],
      "source": [
        "# transformando cada valor do hog_feature em um atributo (coluna)\n",
        "df2 = pd.DataFrame(df['hog_features'].tolist())\n",
        "df2.columns = df2.columns.map(lambda x: f'hog_feature_{x+1}')\n",
        "df = pd.concat([df.drop('hog_features', axis=1), df2], axis=1)\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbgcrkycnuto"
      },
      "outputs": [],
      "source": [
        "# Salvando csv resultante -> pode alterar o tamanho do pixels_per_cell\n",
        "df.to_csv('hog_16x16.csv', sep=';', index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('hog_16x16.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVEhvcHTqEP0"
      },
      "source": [
        "**PCA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrayA2DsqGgR"
      },
      "outputs": [],
      "source": [
        "### Carregar as Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "### Importing Dataset\n",
        "dataset = pd.read_csv('hog_16x16.csv',encoding='utf-8')\n",
        "dataset = pd.read_csv('hog_16x16.csv', header = 0, sep = ',', encoding = 'utf-8',engine='c')\n",
        "\n",
        "### Mostrando as colunas do dataset\n",
        "dataset.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkoXqLTQqfPF"
      },
      "outputs": [],
      "source": [
        "tipos_numericos = ['float64']\n",
        "atributos_numericos = dataset.select_dtypes(include=tipos_numericos)\n",
        "\n",
        "colunas_numericas = list(atributos_numericos.columns)\n",
        "\n",
        "print(colunas_numericas)\n",
        "\n",
        "X = dataset[colunas_numericas] # Features\n",
        "y = dataset.pathfile      # Target variable (classe)\n",
        "\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OHOMKyyqm3R"
      },
      "outputs": [],
      "source": [
        "### Importando PCA do SkLearn #################\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca_obj = PCA(n_components=0.90, whiten=True) #posso alterar a porcentagem\n",
        "pca_result = pca_obj.fit_transform(X)\n",
        "\n",
        "print(pca_result.shape)\n",
        "\n",
        "columns = [\"pca_\"+str(i) for i in range(1,pca_result.shape[1]+1)]\n",
        "\n",
        "print(columns)\n",
        "pca_dataset = pd.DataFrame(data = pca_result, columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca_dataset.head()"
      ],
      "metadata": {
        "id": "qiVI4FPB_6gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-evrLhvqtfK"
      },
      "outputs": [],
      "source": [
        "final_data = pca_dataset.join(y)\n",
        "\n",
        "df = pd.DataFrame(final_data)\n",
        "df.to_csv('hog_16_pca_90.csv', index=False) #posso alterar a porcentagem\n",
        "\n",
        "# Importando arquivo transformado\n",
        "from google.colab import files\n",
        "files.download('hog_16_pca_90.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.head()"
      ],
      "metadata": {
        "id": "mEvn3cwtJwnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NORMALIZANDO OS DADOS E ADICIONANDO O ATRIBUTO CLASSE**\n",
        "- Neste exemplo o atributo classe será 'Cachorro' ou 'Gato' pois o dataset que está sendo utilizado contém imagens de cachorros e gatos."
      ],
      "metadata": {
        "id": "LY0G2kGLHh8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Carregar as Libraries\n",
        "import pandas as pd\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "\n",
        "### Importing Dataset\n",
        "dataset = pd.read_csv('hog_16_pca_90.csv',encoding='utf-8')\n",
        "\n",
        "# Visualização dos atributos\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "VnLroG09AUq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adicionar o atributo classe que determina 'cachorro' ou 'gato'\n",
        "def determinar_classe(row):\n",
        "    if row['pathfile'][0].islower():\n",
        "        return 'cachorro'\n",
        "    else:\n",
        "        return 'gato'\n",
        "dataset['classe'] = dataset.apply(determinar_classe, axis=1)\n",
        "\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "CD3WND0GhWTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normaliza os dados numéricos\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "tipos_numericos = ['float64']\n",
        "cols_num = dataset.select_dtypes(include=tipos_numericos)\n",
        "\n",
        "colunas_numericas = list(cols_num.columns)\n",
        "\n",
        "dados_normalizados = dataset.copy()\n",
        "dados_normalizados[colunas_numericas] = dataset[colunas_numericas].apply(minmax_scale)"
      ],
      "metadata": {
        "id": "GROy7MGUhg2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo os nomes das colunas Numéricas\n",
        "tipos_numericos = ['int32', 'int64', 'float16', 'float32', 'float64']\n",
        "cols_num = dados_normalizados.select_dtypes(include=tipos_numericos)\n",
        "\n",
        "## Selecionando os atributos numéricos\n",
        "colunas_numericas = list(cols_num.columns)\n",
        "\n",
        "## Pegar a classe\n",
        "coluna_classe = dataset['classe']\n",
        "\n",
        "## Separando os atributos da classe\n",
        "X = dataset[colunas_numericas] # Features\n",
        "y = coluna_classe             # Target variable (classe)\n",
        "\n",
        "dados_normalizados.head()"
      ],
      "metadata": {
        "id": "CWfLpI_8hjhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10-fold | Cross Validation**"
      ],
      "metadata": {
        "id": "X9SH2L1wvPln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Carregando o algoritmo / método / técnica k-NN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "## Implementando k-fold CV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "\n",
        "# 10-fold CV\n",
        "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "for i in range(1, 11):\n",
        "  # Instanciando um objeto KNeighborsClassifier\n",
        "  knn = KNeighborsClassifier(n_neighbors=i, metric='euclidean')\n",
        "\n",
        "  # Model Accuracy\n",
        "  scores = cross_val_score(knn, X, y, scoring='accuracy', cv=kf)\n",
        "  print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
        "\n",
        "  # Matriz de confusão p/ kf\n",
        "  y_pred = cross_val_predict(knn, X, y, cv=kf)\n",
        "  confusion_matrix(y, y_pred)"
      ],
      "metadata": {
        "id": "kGyYOytYHqHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10-fold | Holdout**"
      ],
      "metadata": {
        "id": "77cHOz4kvdyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Carregando o algoritmo / método / técnica k-NN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# Separando dataset em duas partes: treinamento e teste\n",
        "# 70% training and 30% test\n",
        "X_train_70, X_test_30, y_train_70, y_test_30 = train_test_split(X, y, test_size=0.10, random_state=1)\n",
        "\n",
        "\n",
        "### Instanciando kNN and varying k from 1 to 10\n",
        "print('HoldOut 70-30')\n",
        "for i in range(1, 11):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i, metric='euclidean')\n",
        "    knn.fit(X_train_70, y_train_70)\n",
        "\n",
        "    # Utilizando a parte de teste para fazer a predição\n",
        "    y_pred = knn.predict(X_test_30)\n",
        "\n",
        "    # Accuracia do Modelo\n",
        "    acuracia = metrics.accuracy_score(y_test_30, y_pred)\n",
        "    print('%d-NN Accuracy: %.3f' % (i, acuracia))"
      ],
      "metadata": {
        "id": "hjs9SP63GVv2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}